{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa30d16413594c5ab0dc5fbd7ef2c88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eef9ba58cdef4ab5bd51676d11c41c90",
              "IPY_MODEL_b21f7c48f69b49d5924ac53291bcc750",
              "IPY_MODEL_c2309fafd5df459abb23618cc5167ba2"
            ],
            "layout": "IPY_MODEL_2d5eb1c62f9a4c418b198bd04604d353"
          }
        },
        "eef9ba58cdef4ab5bd51676d11c41c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ea7dafdefc426faa8efb5c99576314",
            "placeholder": "​",
            "style": "IPY_MODEL_ef4d9049910f48a6b9b8b4e05e6454a9",
            "value": "100%"
          }
        },
        "b21f7c48f69b49d5924ac53291bcc750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d882e9ceae40ddaa58c073217a6c58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d72dce674844636b6150cc083aaf4e2",
            "value": 1
          }
        },
        "c2309fafd5df459abb23618cc5167ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cea7055ed2448bbb3fe6f3d7b32bc6a",
            "placeholder": "​",
            "style": "IPY_MODEL_d2db5dc6962e404e8dfa5601aaca76b5",
            "value": " 1/1 [00:00&lt;00:00, 13.66it/s]"
          }
        },
        "2d5eb1c62f9a4c418b198bd04604d353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ea7dafdefc426faa8efb5c99576314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4d9049910f48a6b9b8b4e05e6454a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d882e9ceae40ddaa58c073217a6c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d72dce674844636b6150cc083aaf4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cea7055ed2448bbb3fe6f3d7b32bc6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2db5dc6962e404e8dfa5601aaca76b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidlin2k/JSC270_A4/blob/main/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "train_url = 'https://github.com/davidlin2k/JSC270_A4/raw/main/Corona_NLP_train.csv'\n",
        "df_train = pd.read_csv(train_url, encoding='latin1')\n",
        "\n",
        "test_url = 'https://github.com/davidlin2k/JSC270_A4/raw/main/Corona_NLP_test.csv'\n",
        "df_test = pd.read_csv(test_url, encoding='latin1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hano6Z60d0zz",
        "outputId": "a4539192-4747-4573-8aff-c2fd8616cd2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I: Sentiment Analysis with a Twitter Dataset "
      ],
      "metadata": {
        "id": "NB5cc_qSdX0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A) Consider the training data. What is the balance between the three classes? In other words, what proportion of the observations (in the training set) belong to each class?"
      ],
      "metadata": {
        "id": "YeJxzr-kdorR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "kIvc6-DtqfT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311f76f3-ff86-47b2-898c-66477a41def9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0    0.374128\n",
              "1    0.187404\n",
              "2    0.438467\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "def map_sentiment(df):\n",
        "  map = {\"Extremely Negative\": 0, \"Negative\": 0, \"Neutral\": 1, \"Positive\": 2, \"Extremely Positive\": 2}\n",
        "  df['Sentiment'].replace(map, inplace=True)\n",
        "\n",
        "map_sentiment(df_train)\n",
        "\n",
        "# Proportion of the observations in each class\n",
        "df_train.groupby('Sentiment').size() / df_train.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B) Tokenize the tweets. In other words, for each observation, convert the tweet from a single string of running text into a list of individual tokens (possibly with punctuation), splitting on whitespace. The result should be that each observation (tweet) is a list of individual tokens.\n"
      ],
      "metadata": {
        "id": "KfhwIHG6kdee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['OriginalTweetTokenized'] = df_train.apply(lambda row: nltk.word_tokenize(row['OriginalTweet']), axis=1)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "U85ns4WVkhKW",
        "outputId": "ef10b77d-62b7-4d74-817a-d92ab74c5c43"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1   \n",
              "1  advice Talk to your neighbours family to excha...          2   \n",
              "2  Coronavirus Australia: Woolworths to give elde...          2   \n",
              "3  My food stock is not the only one which is emp...          2   \n",
              "4  Me, ready to go at supermarket during the #COV...          0   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...   \n",
              "1  [advice, Talk, to, your, neighbours, family, t...   \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...   \n",
              "3  [My, food, stock, is, not, the, only, one, whi...   \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, :, /...  \n",
              "1  [advice, Talk, neighbour, family, exchange, ph...  \n",
              "2  [Coronavirus, Australia, :, Woolworths, give, ...  \n",
              "3  [My, food, stock, not, only, one, empty, ..., ...  \n",
              "4  [Me, ,, ready, go, supermarket, #, COVID19, ou...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4e0e9c1-7174-43f5-ad9c-86d381c2a090\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, :, /...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "      <td>[advice, Talk, neighbour, family, exchange, ph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, give, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>[My, food, stock, not, only, one, empty, ..., ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "      <td>[Me, ,, ready, go, supermarket, #, COVID19, ou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4e0e9c1-7174-43f5-ad9c-86d381c2a090')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4e0e9c1-7174-43f5-ad9c-86d381c2a090 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4e0e9c1-7174-43f5-ad9c-86d381c2a090');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C) Using a regular expression, remove any URL tokens from each of the observations. \n",
        "Hint: In this dataset, all such tokens begin with “http”."
      ],
      "metadata": {
        "id": "jbszxHRBls67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_pattern = r'http\\S+'\n",
        "\n",
        "df_train['OriginalTweetTokenizedCleaned'] = df_train['OriginalTweetTokenized'].apply(lambda x: [token for token in x if not re.match(url_pattern, token)])\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Ou9FOPYblyVR",
        "outputId": "de8687de-1559-4921-9dcc-6ff3970843ea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1   \n",
              "1  advice Talk to your neighbours family to excha...          2   \n",
              "2  Coronavirus Australia: Woolworths to give elde...          2   \n",
              "3  My food stock is not the only one which is emp...          2   \n",
              "4  Me, ready to go at supermarket during the #COV...          0   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...   \n",
              "1  [advice, Talk, to, your, neighbours, family, t...   \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...   \n",
              "3  [My, food, stock, is, not, the, only, one, whi...   \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, :, /...  \n",
              "1  [advice, Talk, to, your, neighbours, family, t...  \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...  \n",
              "3  [My, food, stock, is, not, the, only, one, whi...  \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3dc4ee0-7db5-4062-8104-8fbd2958ace0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, :, /...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3dc4ee0-7db5-4062-8104-8fbd2958ace0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3dc4ee0-7db5-4062-8104-8fbd2958ace0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3dc4ee0-7db5-4062-8104-8fbd2958ace0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D) Remove all punctuation (,.?!;:’\") and special characters(@, #, +, &, =, $, etc). Also, convert all tokens to lowercase only. Can you think of a scenario when you might want to keep some forms of punctuation?"
      ],
      "metadata": {
        "id": "DRTGbXpRmaAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "punct_pattern = r'[{}]'.format(string.punctuation + '’”“”')\n",
        "\n",
        "df_train['OriginalTweetTokenizedCleaned'] = df_train['OriginalTweetTokenizedCleaned'].apply(lambda x: [re.sub(punct_pattern, '', token).lower() for token in x])\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "MS30LKbOmf3S",
        "outputId": "99e895dd-0242-4925-c21f-1d1ce20016be"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1   \n",
              "1  advice Talk to your neighbours family to excha...          2   \n",
              "2  Coronavirus Australia: Woolworths to give elde...          2   \n",
              "3  My food stock is not the only one which is emp...          2   \n",
              "4  Me, ready to go at supermarket during the #COV...          0   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...   \n",
              "1  [advice, Talk, to, your, neighbours, family, t...   \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...   \n",
              "3  [My, food, stock, is, not, the, only, one, whi...   \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [, menyrbie, , philgahan, , chrisitv, , tcoifz...  \n",
              "1  [advice, talk, to, your, neighbours, family, t...  \n",
              "2  [coronavirus, australia, , woolworths, to, giv...  \n",
              "3  [my, food, stock, is, not, the, only, one, whi...  \n",
              "4  [me, , ready, to, go, at, supermarket, during,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b5c9d5c-2e21-44c3-9529-f59422bf7460\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...</td>\n",
              "      <td>[, menyrbie, , philgahan, , chrisitv, , tcoifz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "      <td>[coronavirus, australia, , woolworths, to, giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "      <td>[me, , ready, to, go, at, supermarket, during,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b5c9d5c-2e21-44c3-9529-f59422bf7460')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b5c9d5c-2e21-44c3-9529-f59422bf7460 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b5c9d5c-2e21-44c3-9529-f59422bf7460');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E) Now stem your tokens. This will have the effect of converting similar word forms into identical tokens (e.g. run, runs, running → run). Please specify which stemmer you use. "
      ],
      "metadata": {
        "id": "hHIkruxdnMlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "df_train['OriginalTweetTokenizedCleaned'] = df_train['OriginalTweetTokenizedCleaned'].apply(stem_tokens)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "B542by-QnjWP",
        "outputId": "b55e65d3-8a68-434c-daa1-8ef20e5ff11a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1   \n",
              "1  advice Talk to your neighbours family to excha...          2   \n",
              "2  Coronavirus Australia: Woolworths to give elde...          2   \n",
              "3  My food stock is not the only one which is emp...          2   \n",
              "4  Me, ready to go at supermarket during the #COV...          0   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...   \n",
              "1  [advice, Talk, to, your, neighbours, family, t...   \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...   \n",
              "3  [My, food, stock, is, not, the, only, one, whi...   \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [, menyrbi, , philgahan, , chrisitv, , tcoifz9...  \n",
              "1  [advic, talk, to, your, neighbour, famili, to,...  \n",
              "2  [coronaviru, australia, , woolworth, to, give,...  \n",
              "3  [my, food, stock, is, not, the, onli, one, whi...  \n",
              "4  [me, , readi, to, go, at, supermarket, dure, t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-153c0329-64b7-4dcc-b389-5702b2c2fe45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...</td>\n",
              "      <td>[, menyrbi, , philgahan, , chrisitv, , tcoifz9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "      <td>[advic, talk, to, your, neighbour, famili, to,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "      <td>[coronaviru, australia, , woolworth, to, give,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>[my, food, stock, is, not, the, onli, one, whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "      <td>[me, , readi, to, go, at, supermarket, dure, t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-153c0329-64b7-4dcc-b389-5702b2c2fe45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-153c0329-64b7-4dcc-b389-5702b2c2fe45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-153c0329-64b7-4dcc-b389-5702b2c2fe45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F) Lastly, remove stopwords. Using the english stopwords list from nltk, remove these common words from your observations. This list is very long (I think almost 200 words), so remove only the first 100 stopwords in the list."
      ],
      "metadata": {
        "id": "VSkn7lUNolS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english')[:100])\n",
        "def remove_stopwords(tokens):\n",
        "    return [token for token in tokens if token not in stop_words and token != '']\n",
        "\n",
        "df_train['OriginalTweetTokenizedCleaned'] = df_train['OriginalTweetTokenizedCleaned'].apply(remove_stopwords)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "TQda_5N6orqS",
        "outputId": "397a0dd4-0c74-45b2-9e5f-0b8fe5878cbf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          1   \n",
              "1  advice Talk to your neighbours family to excha...          2   \n",
              "2  Coronavirus Australia: Woolworths to give elde...          2   \n",
              "3  My food stock is not the only one which is emp...          2   \n",
              "4  Me, ready to go at supermarket during the #COV...          0   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...   \n",
              "1  [advice, Talk, to, your, neighbours, family, t...   \n",
              "2  [Coronavirus, Australia, :, Woolworths, to, gi...   \n",
              "3  [My, food, stock, is, not, the, only, one, whi...   \n",
              "4  [Me, ,, ready, to, go, at, supermarket, during...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [menyrbi, philgahan, chrisitv, tcoifz9fan2pa, ...  \n",
              "1  [advic, talk, neighbour, famili, exchang, phon...  \n",
              "2  [coronaviru, australia, woolworth, give, elder...  \n",
              "3  [food, stock, not, onli, one, empti, pleas, nt...  \n",
              "4  [readi, go, supermarket, dure, covid19, outbre...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8985b14-57b8-47ea-aeb4-716e59ae6ecf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>1</td>\n",
              "      <td>[@, MeNyrbie, @, Phil_Gahan, @, Chrisitv, http...</td>\n",
              "      <td>[menyrbi, philgahan, chrisitv, tcoifz9fan2pa, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>2</td>\n",
              "      <td>[advice, Talk, to, your, neighbours, family, t...</td>\n",
              "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Coronavirus, Australia, :, Woolworths, to, gi...</td>\n",
              "      <td>[coronaviru, australia, woolworth, give, elder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>2</td>\n",
              "      <td>[My, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>[food, stock, not, onli, one, empti, pleas, nt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Me, ,, ready, to, go, at, supermarket, during...</td>\n",
              "      <td>[readi, go, supermarket, dure, covid19, outbre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8985b14-57b8-47ea-aeb4-716e59ae6ecf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8985b14-57b8-47ea-aeb4-716e59ae6ecf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8985b14-57b8-47ea-aeb4-716e59ae6ecf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G) Now convert your lists of words into vectors of word counts. You may find Scikit-learn’s CountVectorizer useful here. What is the length of your vocabulary? "
      ],
      "metadata": {
        "id": "ZrMltc_0p39G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "X, y = df_train['OriginalTweetTokenizedCleaned'], df_train['Sentiment']\n",
        "\n",
        "def override_fcn(doc):\n",
        "  return doc\n",
        "\n",
        "count_vec = CountVectorizer()\n",
        "\n",
        "X_train = count_vec.fit_transform(X.apply(\" \".join))\n",
        "print(len(count_vec.vocabulary_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqjyf2TPp9E3",
        "outputId": "8c5999b5-eee4-4b45-bb5f-30ebde09e919"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### H) Recall the definition of the Naive Bayes model. If each document (tweet) is a collection of words (w1, · · · , wN ) belonging to class Ck (k = 0, 1, 2), then the Naive Bayes approach models the probability of each tweet belonging to class k:\n",
        "\n",
        "The last equality follows from our “naive” assumption that words are conditionally independent given class. The probabilities are estimated using the frequencies of words within each class (bag of words), and we assign the class label according to which of the 3 posterior class probabilities (P(Ck|w1,··· ,wN)) is the highest.\n",
        "\n",
        "Fit a Naive Bayes model to your data. Report the training and test error of the model. Use accuracy as the error metric. Also, report the 5 most probable words in each class, along with their counts. You might find Scikit-learn’s MultinomialNB() transformer useful. Use Laplace smoothing to prevent probabilities of zero.\n"
      ],
      "metadata": {
        "id": "bOGMyrJxx2ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_df(df, col, new_col):\n",
        "  # B)\n",
        "  df['OriginalTweetTokenized'] = df.apply(lambda row: nltk.word_tokenize(row[col]), axis=1)\n",
        "  \n",
        "  # C)\n",
        "  url_pattern = r'http\\S+'\n",
        "  df[new_col] = df['OriginalTweetTokenized'].apply(lambda x: [token for token in x if not re.match(url_pattern, token)])\n",
        "\n",
        "  # D)\n",
        "  punct_pattern = r'[{}]'.format(string.punctuation + '’”“”' + string.digits)\n",
        "  df[new_col] = df[new_col].apply(lambda x: [re.sub(punct_pattern, '', token).lower() for token in x])\n",
        "\n",
        "  # E)\n",
        "  stemmer = PorterStemmer()\n",
        "  df[new_col] = df[new_col].apply(stem_tokens)\n",
        "\n",
        "  # F)\n",
        "  stop_words = set(stopwords.words('english')[:100])\n",
        "  df[new_col] = df[new_col].apply(remove_stopwords)\n",
        "\n",
        "map_sentiment(df_test)\n",
        "clean_df(df_test, 'OriginalTweet', 'OriginalTweetTokenizedCleaned')\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "C8jHH249x9N4",
        "outputId": "e76ce6aa-025b-4df6-cc28-ad6f7b8f56fc"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName             Location     TweetAt  \\\n",
              "0         1       44953                  NYC  02-03-2020   \n",
              "1         2       44954          Seattle, WA  02-03-2020   \n",
              "2         3       44955                  NaN  02-03-2020   \n",
              "3         4       44956          Chicagoland  02-03-2020   \n",
              "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
              "\n",
              "                                       OriginalTweet  Sentiment  \\\n",
              "0  TRENDING: New Yorkers encounter empty supermar...          0   \n",
              "1  When I couldn't find hand sanitizer at Fred Me...          2   \n",
              "2  Find out how you can protect yourself and love...          2   \n",
              "3  #Panic buying hits #NewYork City as anxious sh...          0   \n",
              "4  #toiletpaper #dunnypaper #coronavirus #coronav...          1   \n",
              "\n",
              "                              OriginalTweetTokenized  \\\n",
              "0  [TRENDING, :, New, Yorkers, encounter, empty, ...   \n",
              "1  [When, I, could, n't, find, hand, sanitizer, a...   \n",
              "2  [Find, out, how, you, can, protect, yourself, ...   \n",
              "3  [#, Panic, buying, hits, #, NewYork, City, as,...   \n",
              "4  [#, toiletpaper, #, dunnypaper, #, coronavirus...   \n",
              "\n",
              "                       OriginalTweetTokenizedCleaned  \n",
              "0  [trend, new, yorker, encount, empti, supermark...  \n",
              "1  [when, could, nt, find, hand, sanit, fred, mey...  \n",
              "2   [find, how, can, protect, love, one, coronaviru]  \n",
              "3  [panic, buy, hit, newyork, citi, anxiou, shopp...  \n",
              "4  [toiletpap, dunnypap, coronaviru, coronavirusa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e393213c-4635-47ab-8e4c-d789319aa6a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>OriginalTweetTokenized</th>\n",
              "      <th>OriginalTweetTokenizedCleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>0</td>\n",
              "      <td>[TRENDING, :, New, Yorkers, encounter, empty, ...</td>\n",
              "      <td>[trend, new, yorker, encount, empti, supermark...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>2</td>\n",
              "      <td>[When, I, could, n't, find, hand, sanitizer, a...</td>\n",
              "      <td>[when, could, nt, find, hand, sanit, fred, mey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Find, out, how, you, can, protect, yourself, ...</td>\n",
              "      <td>[find, how, can, protect, love, one, coronaviru]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>[#, Panic, buying, hits, #, NewYork, City, as,...</td>\n",
              "      <td>[panic, buy, hit, newyork, citi, anxiou, shopp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>1</td>\n",
              "      <td>[#, toiletpaper, #, dunnypaper, #, coronavirus...</td>\n",
              "      <td>[toiletpap, dunnypap, coronaviru, coronavirusa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e393213c-4635-47ab-8e4c-d789319aa6a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e393213c-4635-47ab-8e4c-d789319aa6a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e393213c-4635-47ab-8e4c-d789319aa6a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train = df_train['Sentiment']\n",
        "X_test, y_test = df_test['OriginalTweetTokenizedCleaned'], df_test['Sentiment']\n",
        "\n",
        "X_test = count_vec.transform(X_test.apply(\" \".join))\n",
        "\n",
        "# Let's fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "# Fit model to training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_preds = nb.predict(X_train)\n",
        "print('Test accuracy with simple Naive Bayes on training data:', accuracy_score(y_train, y_preds))\n",
        "\n",
        "y_preds = nb.predict(X_test)\n",
        "print('Test accuracy with simple Naive Bayes on test data:', accuracy_score(y_test, y_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA5Nvb6dsQRH",
        "outputId": "b0141b0a-0ead-4568-f50d-313b3fa21ab5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes on training data: 0.8179896493913551\n",
            "Test accuracy with simple Naive Bayes on test data: 0.6700895208004213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vec.get_feature_names_out()\n",
        "class_labels = nb.classes_\n",
        "\n",
        "label_to_category = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "for label in class_labels:\n",
        "    i = class_labels.tolist().index(label)\n",
        "\n",
        "    indices = nb.feature_log_prob_[i].argsort()[-5:][::-1]\n",
        "    words = [feature_names[index] for index in indices]\n",
        "    counts = [nb.feature_count_[i][index] for index in indices]\n",
        "    print(label_to_category[i], list(zip(words, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izP80vYkqev4",
        "outputId": "6d27aa2c-285b-4abc-e03d-5d15d403aa72"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative [('coronaviru', 6737.0), ('covid19', 5816.0), ('price', 4349.0), ('food', 3641.0), ('thi', 3229.0)]\n",
            "Neutral [('coronaviru', 3812.0), ('covid19', 3220.0), ('store', 1589.0), ('supermarket', 1444.0), ('price', 1365.0)]\n",
            "Positive [('coronaviru', 7513.0), ('covid19', 7066.0), ('store', 3918.0), ('thi', 3798.0), ('price', 3342.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I) Would it be appropriate to fit an ROC curve in this scenario? If yes, explain why. If no, explain why not.\n"
      ],
      "metadata": {
        "id": "MFSE7sGyonyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, it would not be appropriate to fit an ROC curve in this scenario.\n",
        "\n",
        "An ROC curve is a graphical representation of the performance of a binary classifier system as the discrimination threshold is varied. In other words, it is a tool for evaluating the performance of a model that predicts a binary outcome based on a continuous score. However, in this scenario, the model predicts the probability of each tweet belonging to one of three classes based on the frequencies of words within each class.\n",
        "\n",
        "Therefore, fitting an ROC curve is not appropriate in this scenario because it is not a binary classification problem and the model does not predict a continuous score. Instead, we can use evaluation metrics such as accuracy, precision, recall, and F1-score to evaluate the performance of the Naive Bayes model."
      ],
      "metadata": {
        "id": "bsdvZCJZotx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J) Redo parts G-H using TF-IDF vectors instead of count vectors. You might find Scikitlearn’s TfidfVectorizer() transformer useful. Report the training and test accuracy. How does this compare to the accuracy using count vectors?  \n"
      ],
      "metadata": {
        "id": "k6GDtCjTvDGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train, y_train = df_train['OriginalTweetTokenizedCleaned'], df_train['Sentiment']\n",
        "X_test, y_test = df_test['OriginalTweetTokenizedCleaned'], df_test['Sentiment']\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "\n",
        "X_train = tfidf_vec.fit_transform(X_train.apply(\" \".join))\n",
        "X_test = tfidf_vec.transform(X_test.apply(\" \".join))\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_preds = nb.predict(X_train)\n",
        "print('Test accuracy with simple Naive Bayes on training data:', accuracy_score(y_train, y_preds))\n",
        "\n",
        "y_preds = nb.predict(X_test)\n",
        "print('Test accuracy with simple Naive Bayes on test data:', accuracy_score(y_test, y_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no8SnF28vxvP",
        "outputId": "807ce3ba-a7f5-4b3c-aea2-43fc27a30ce4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes on training data: 0.7256359792987828\n",
            "Test accuracy with simple Naive Bayes on test data: 0.6237493417588205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf_vec.get_feature_names_out()\n",
        "class_labels = nb.classes_\n",
        "\n",
        "label_to_category = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "for label in class_labels:\n",
        "    i = class_labels.tolist().index(label)\n",
        "\n",
        "    indices = nb.feature_log_prob_[i].argsort()[-5:][::-1]\n",
        "    words = [feature_names[index] for index in indices]\n",
        "    counts = [nb.feature_count_[i][index] for index in indices]\n",
        "    print(label_to_category[i], list(zip(words, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "946IPkKcx3CV",
        "outputId": "046fc0de-cc7e-45c5-e851-23149c441eaf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative [('coronaviru', 446.1102607737225), ('covid19', 401.8190307962107), ('price', 390.11029529303096), ('food', 369.9140312787462), ('thi', 302.4997366031556)]\n",
            "Neutral [('coronaviru', 284.8050794748103), ('covid19', 253.53289190750993), ('store', 184.43590109005157), ('supermarket', 166.6960173162174), ('groceri', 159.36920313190842)]\n",
            "Positive [('coronaviru', 490.5219327784592), ('covid19', 479.5335481558695), ('store', 383.6869648967932), ('thi', 357.30512159482663), ('groceri', 344.07817958665845)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the accuracy reported with simple Naive Bayes, we can see that with Tfidf Vectorizer, the accuracy has slightly when comparing to both the training data and the testing data."
      ],
      "metadata": {
        "id": "UJUSdB9dyPDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K) Recall lemmatization converts each word to its base form, which is a bit stronger than simply taking the stem. Redo parts E-H using TF-IDF vectors instead of count vectors. This time use lemmatization instead of stemming. Report train and test accuracy. How does the accuracy with lemmatization compare to the accuracy with stemming? "
      ],
      "metadata": {
        "id": "0Bp9C9-dynXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def lemmatize_df(df):\n",
        "  df['OriginalTweetTokenizedCleaned'] = df['OriginalTweetTokenized'].apply(lambda x: [token for token in x if not re.match(url_pattern, token)])\n",
        "  df['OriginalTweetTokenizedCleaned'] = df['OriginalTweetTokenizedCleaned'].apply(lemmatize_tokens)\n",
        "  df['OriginalTweetTokenizedCleaned'] = df['OriginalTweetTokenizedCleaned'].apply(remove_stopwords)\n",
        "\n",
        "lemmatize_df(df_train)\n",
        "lemmatize_df(df_test)"
      ],
      "metadata": {
        "id": "OUNMU_pvzfrv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train['OriginalTweetTokenizedCleaned']\n",
        "X_test = df_test['OriginalTweetTokenizedCleaned']\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "\n",
        "X_train = tfidf_vec.fit_transform(X_train.apply(\" \".join))\n",
        "X_test = tfidf_vec.transform(X_test.apply(\" \".join))\n",
        "\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_preds = nb.predict(X_train)\n",
        "print('Test accuracy with simple Naive Bayes on training data:', accuracy_score(y_train, y_preds))\n",
        "\n",
        "y_preds = nb.predict(X_test)\n",
        "print('Test accuracy with simple Naive Bayes on test data:', accuracy_score(y_test, y_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Q58JsB0dIN",
        "outputId": "10e63e5e-3980-4212-a9ec-d835981302ed"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes on training data: 0.7329737347231333\n",
            "Test accuracy with simple Naive Bayes on test data: 0.6182201158504476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf_vec.get_feature_names_out()\n",
        "class_labels = nb.classes_\n",
        "\n",
        "label_to_category = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "for label in class_labels:\n",
        "    i = class_labels.tolist().index(label)\n",
        "\n",
        "    indices = nb.feature_log_prob_[i].argsort()[-5:][::-1]\n",
        "    words = [feature_names[index] for index in indices]\n",
        "    counts = [nb.feature_count_[i][index] for index in indices]\n",
        "    print(label_to_category[i], list(zip(words, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDzOIkDj1kJj",
        "outputId": "382aeb9e-2c9a-4379-e653-3aca2369ea13"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative [('co', 453.96663660547733), ('coronavirus', 428.47109342382623), ('19', 363.16706855905556), ('price', 357.6478954549523), ('food', 356.2430111110362)]\n",
            "Neutral [('co', 360.9533163580895), ('coronavirus', 273.7238338258587), ('19', 192.24152404344423), ('covid', 189.0139259698027), ('store', 174.1831420076595)]\n",
            "Positive [('co', 580.0481703638764), ('coronavirus', 471.38951797648997), ('19', 402.50290587739954), ('covid', 389.65844824333794), ('store', 366.130771261546)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the accuracy reported, it seems that the accuracy is very similar to when we lemmatize the tokens instead of stemming them."
      ],
      "metadata": {
        "id": "_mDJ4_YZ2oQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Having fun with NLP using the Twitter API"
      ],
      "metadata": {
        "id": "nPxjSw1X25pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/davidlin2k/JSC270_A4/main/tweets.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "zlqqAr9n5R-Q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (I) Problem description and motivation"
      ],
      "metadata": {
        "id": "f2tNTx9TQd4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRtEIqi5qwTa",
        "outputId": "9c2e0912-2ba8-444e-ec5a-43cb012f7528"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"nomic-ai/gpt4all_prompt_generations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "fa30d16413594c5ab0dc5fbd7ef2c88c",
            "eef9ba58cdef4ab5bd51676d11c41c90",
            "b21f7c48f69b49d5924ac53291bcc750",
            "c2309fafd5df459abb23618cc5167ba2",
            "2d5eb1c62f9a4c418b198bd04604d353",
            "e9ea7dafdefc426faa8efb5c99576314",
            "ef4d9049910f48a6b9b8b4e05e6454a9",
            "89d882e9ceae40ddaa58c073217a6c58",
            "3d72dce674844636b6150cc083aaf4e2",
            "6cea7055ed2448bbb3fe6f3d7b32bc6a",
            "d2db5dc6962e404e8dfa5601aaca76b5"
          ]
        },
        "id": "TJ-uaaedpOuQ",
        "outputId": "462f3397-fbc9-48cf-98ff-cb5974705a82"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/nomic-ai___parquet/nomic-ai--gpt4all_prompt_generations-49baa4c0ec461c33/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa30d16413594c5ab0dc5fbd7ef2c88c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({'text': dataset['train']['response'][:10000], 'generated': 1})\n",
        "df2 = pd.DataFrame({'text': df['tweet_text'], 'generated': 0})\n",
        "\n",
        "new_df = pd.concat([df1, df2])\n",
        "\n",
        "clean_df(new_df, 'text', 'clean_text')"
      ],
      "metadata": {
        "id": "3towk605pknw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (II) Describe the data"
      ],
      "metadata": {
        "id": "YCgf-fIzQfvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.groupby('generated').size() / new_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbWLE2_Pt5Cq",
        "outputId": "c3a8d884-3d17-43ba-ac18-8187c2d0c954"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generated\n",
              "1    0.5\n",
              "2    0.5\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (III) Exploratory data analysis"
      ],
      "metadata": {
        "id": "52aXlRXMQj9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = new_df['clean_text'], new_df['generated'].to_numpy()"
      ],
      "metadata": {
        "id": "BioCC-C7tlxa"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
        "\n",
        "print(X_test)\n",
        "\n",
        "X_train = count_vec.fit_transform(X_train.apply(\" \".join))\n",
        "X_test = count_vec.transform(X_test.apply(\" \".join))\n",
        "\n",
        "\n",
        "# Let's fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "# Fit model to training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "y_preds = nb.predict(X_test)\n",
        "print('Test accuracy with simple Naive Bayes on test data:', accuracy_score(y_test, y_preds))\n",
        "\n",
        "y_preds = nb.predict(count_vec.transform([\"hello world\"]))\n",
        "\n",
        "print(y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ov4hoKZQ2QQ",
        "outputId": "c36a0319-7510-4ed7-edf0-b3f59960f08d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "650     [y, all, forget, sign, year, deal, china, cdnp...\n",
            "2041    [s, hard, tell, exactli, s, go, wrong, without...\n",
            "8668    [ai, languag, model, not, abil, run, vba, code...\n",
            "1114    [can, keep, track, all, indic, where, target, ...\n",
            "3902    [s, crazi, whole, countri, franc, stand, gover...\n",
            "                              ...                        \n",
            "7382    [ai, languag, model, nt, use, fbp, real, proje...\n",
            "3492    [seansimonian, revdaniel, poilievr, fascist, a...\n",
            "394     [still, wonder, trudeau, s, employ, 🤔, cdnpoli...\n",
            "6865    [pmjt, name, guest, highlight, canadau, partne...\n",
            "5047    [move, marker, accord, latlng, valu, obtain, g...\n",
            "Name: clean_text, Length: 16000, dtype: object\n",
            "Test accuracy with simple Naive Bayes on test data: 0.993625\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(word):\n",
        "  y_preds = nb.predict(count_vec.transform([word]))\n",
        "  print(y_preds[0])"
      ],
      "metadata": {
        "id": "nMDhW_UK0ZxB"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (IV) Describe your machine learning model"
      ],
      "metadata": {
        "id": "nNslkcB9QmYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (V) Results and Conclusions"
      ],
      "metadata": {
        "id": "6AefQ1lNQpP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interactive Player"
      ],
      "metadata": {
        "id": "_rf80gzn1GiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"\"\n",
        "\n",
        "predict(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9efdQC9i0WAq",
        "outputId": "41d1bd9e-d527-4234-9cec-c23100a81cca"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vec.get_feature_names_out()\n",
        "class_labels = nb.classes_\n",
        "\n",
        "label_to_category = [\"Tweet\", \"AI\"]\n",
        "\n",
        "for label in class_labels:\n",
        "    i = class_labels.tolist().index(label)\n",
        "\n",
        "    indices = nb.feature_log_prob_[i].argsort()[-5:][::-1]\n",
        "    words = [feature_names[index] for index in indices]\n",
        "    counts = [nb.feature_count_[i][index] for index in indices]\n",
        "    print(label_to_category[i], list(zip(words, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AO7fH6g1PyE",
        "outputId": "1c86885f-1664-422c-8994-a9343b122c4e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet [('cdnpoli', 693.0), ('thi', 288.0), ('canada', 233.0), ('not', 188.0), ('canadian', 165.0)]\n",
            "AI [('code', 5016.0), ('use', 3905.0), ('thi', 3444.0), ('can', 3105.0), ('file', 1596.0)]\n"
          ]
        }
      ]
    }
  ]
}